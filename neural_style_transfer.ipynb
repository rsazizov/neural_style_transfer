{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "neural_style_transfer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wB0H9R0noORV",
        "colab_type": "text"
      },
      "source": [
        "# Neural Style Transfer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6c3b7JSNevOy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from PIL import Image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxNMTtpvevO5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feature_extractor = keras.applications.vgg19.VGG19(include_top=False, input_shape=(600, 600, 3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zu5vReMNHEwx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The authors suggest to use average pooling instead of max pooling.\n",
        "new_layers = []\n",
        "\n",
        "for i, layer in enumerate(feature_extractor.layers):\n",
        "    if isinstance(layer, keras.layers.MaxPooling2D):\n",
        "        avg_pool = keras.layers.AvgPool2D()\n",
        "        avg_pool.set_weights(layer.get_weights())\n",
        "    \n",
        "        new_layers.append(avg_pool)\n",
        "    else:\n",
        "        new_layers.append(layer)\n",
        "\n",
        "feature_extractor_avg = keras.Sequential(layers=new_layers)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlR2AdjxIITW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feature_extractor_avg.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "6DmKnkuKevO9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def img_to_array(path):\n",
        "    img = keras.preprocessing.image.load_img(path, target_size=(600, 600))\n",
        "    arr = keras.preprocessing.image.img_to_array(img)\n",
        "    return keras.applications.vgg19.preprocess_input(arr)\n",
        "\n",
        "def array_to_image(arr):\n",
        "    return keras.preprocessing.image.array_to_img(arr)\n",
        "\n",
        "# Perform the inverse of the preprocessing step.\n",
        "def vgg19_deprocess_img(processed_img):\n",
        "    x = processed_img.copy()\n",
        "\n",
        "    x[:, :, 0] += 103.939\n",
        "    x[:, :, 1] += 116.779\n",
        "    x[:, :, 2] += 123.68\n",
        "    x = x[:, :, ::-1]\n",
        "\n",
        "    return np.clip(x, 0, 255).astype(np.uint8)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLta4eUrevPB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_features(inputs, layers):\n",
        "    features = dict.fromkeys(layers)\n",
        "    \n",
        "    inputs = tf.expand_dims(inputs, 0)\n",
        "    activations = [inputs]\n",
        "        \n",
        "    for layer in feature_extractor_avg.layers:\n",
        "        activations.append(layer(activations[-1]))\n",
        "        \n",
        "        if layer.name in layers:\n",
        "            features[layer.name] = activations[-1]\n",
        "            \n",
        "    return features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "L6D8lUe0evPG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def content_loss(content, gen, layer='block5_conv2'):\n",
        "    content_features = extract_features(content, (layer,))[layer]\n",
        "    gen_features = extract_features(gen, (layer,))[layer]\n",
        "    \n",
        "    loss = tf.reduce_mean((gen_features - content_features) ** 2)\n",
        "    \n",
        "    return 0.5 * loss\n",
        "\n",
        "def layer_style_loss(style_features, gen_features):\n",
        "    style_features = style_features[0]\n",
        "    gen_features = gen_features[0]\n",
        "\n",
        "    # Number of channels\n",
        "    n_c = style_features.shape[2]\n",
        "    \n",
        "    # Feature map size\n",
        "    fm_size = gen_features.shape[0] * gen_features.shape[1]\n",
        "    \n",
        "    style_features = tf.reshape(style_features, (fm_size, n_c))\n",
        "    gen_features= tf.reshape(gen_features, (fm_size, n_c))\n",
        "   \n",
        "    style_features = tf.transpose(style_features)\n",
        "    gen_features = tf.transpose(gen_features)\n",
        "    \n",
        "    gram_eq = 'ik,jk->ij'\n",
        "    style_gram = tf.einsum(gram_eq, style_features, style_features)\n",
        "    gen_gram = tf.einsum(gram_eq, gen_features, gen_features)\n",
        "    \n",
        "    loss = tf.norm(style_gram - gen_gram) ** 2\n",
        "    norm_factor = 1 / (4 * (n_c ** 2) * (fm_size ** 2))\n",
        "    \n",
        "    return loss * norm_factor\n",
        "\n",
        "def style_loss(style, gen, layers):\n",
        "    style_features = extract_features(style, layers)\n",
        "    gen_features = extract_features(gen, layers)\n",
        "    \n",
        "    style_loss = 0\n",
        "    weight = 1.0 / len(layers)\n",
        "\n",
        "    for layer in layers:\n",
        "        style_loss += layer_style_loss(gen_features[layer],\n",
        "                                       style_features[layer]) * weight \n",
        "\n",
        "    return style_loss\n",
        "\n",
        "def nst_loss(gen, content, style):\n",
        "    style_layers = ('block1_conv1', 'block2_conv1', 'block3_conv1',\n",
        "                    'block4_conv1','block5_conv1',)\n",
        "\n",
        "    alpha = 1e4\n",
        "    beta = 1e-2\n",
        "\n",
        "    content_loss = alpha * content_loss(content, gen)\n",
        "    style_loss = beta * style_loss(style, gen, style_layers)\n",
        "\n",
        "    return content_loss + style_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tGSUJZKevPL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "content = tf.Variable(img_to_array('./data/zurich.jpg'))\n",
        "style = tf.Variable(img_to_array('./data/starry_night.jpg'))\n",
        "\n",
        "image = np.random.uniform(10, 200, size=(600, 600, 3))\n",
        "image = keras.applications.vgg19.preprocess_input(image)\n",
        "image = tf.Variable(image.astype(np.float32))\n",
        "\n",
        "# train\n",
        "n_epochs = 500\n",
        "\n",
        "optim = keras.optimizers.Adam(learning_rate=10, beta_1=0.99, epsilon=1e-1)\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    with tf.GradientTape() as tape:\n",
        "        total_loss = nst_loss(image, content, style)\n",
        "\n",
        "    grad = tape.gradient(total_loss, image)\n",
        "    \n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f'Epoch {epoch + 1}/{n_epochs} - max grad: {tf.reduce_max(grad):.5f}\\\n",
        "                total loss: {total_loss/1000:.4f}k')\n",
        "    \n",
        "    optim.apply_gradients([(grad, image)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqIRShECevPT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np_image = vgg19_deprocess_img(image.numpy())\n",
        "\n",
        "plt.imshow(np_image, aspect='auto')\n",
        "plt.grid(False)\n",
        "plt.axis('off')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dkQNRgPevPd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img = Image.fromarray(np_image)\n",
        "img.save('result_zurich.png')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}